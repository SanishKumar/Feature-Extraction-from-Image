{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwkD-MAmY6VO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import time\n",
        "from time import time as timer\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import requests\n",
        "import urllib\n",
        "from PIL import Image\n",
        "\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'maximum_weight_recommendation': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre',\n",
        "        'cubic foot',\n",
        "        'cubic inch',\n",
        "        'cup',\n",
        "        'decilitre',\n",
        "        'fluid ounce',\n",
        "        'gallon',\n",
        "        'imperial gallon',\n",
        "        'litre',\n",
        "        'microlitre',\n",
        "        'millilitre',\n",
        "        'pint',\n",
        "        'quart'}\n",
        "}\n",
        "\n",
        "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
        "\n",
        "# # Download function\n",
        "# def download_images(image_urls, save_dir):\n",
        "#     if not os.path.exists(save_dir):\n",
        "#         os.makedirs(save_dir)\n",
        "#     for url in tqdm(image_urls):\n",
        "#         img_name = os.path.join(save_dir, url.split(\"/\")[-1])\n",
        "#         img_data = requests.get(url).content\n",
        "#         with open(img_name, 'wb') as handler:\n",
        "#             handler.write(img_data)\n",
        "def create_placeholder_image(image_save_path):\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "    except Exception as e:\n",
        "        return\n",
        "\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    if not isinstance(image_link, str):\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(64) as pool:\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n",
        "# # Download train and test images\n",
        "train_df = pd.read_csv('dataset/train.csv')\n",
        "test_df = pd.read_csv('dataset/test.csv')\n",
        "\n",
        "# download_images(train_df['image_link'], 'train_images', allow_multiprocessing=True)\n",
        "# download_images(test_df['image_link'], 'test_images', allow_multiprocessing=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the unique entities\n",
        "print(\"train datafframe columns : \",train_df.columns)\n",
        "\n",
        "print(\"unique entity name: \",train_df['entity_name'].unique())\n",
        "print(\"unique entity value: \",train_df['entity_value'].unique())\n",
        "\n",
        "import re\n",
        "\n",
        "# Define a function to handle different entity_value formats\n",
        "def extract_numeric_value_and_unit(value):\n",
        "    # Handle ranges (e.g., '6 kilogram to 9 kilogram')\n",
        "    range_pattern = r'(\\d+\\.?\\d*)\\s?([a-zA-Z]+)\\s?to\\s?(\\d+\\.?\\d*)\\s?([a-zA-Z]+)'\n",
        "    list_pattern = r'\\[([\\d+,?\\s]+)\\]\\s?([a-zA-Z]+)'\n",
        "    single_value_pattern = r'(\\d+\\.?\\d*)\\s?([a-zA-Z]+)'\n",
        "\n",
        "    # Check for ranges\n",
        "    range_match = re.match(range_pattern, value)\n",
        "    if range_match:\n",
        "        value1 = float(range_match.group(1))\n",
        "        unit1 = range_match.group(2)\n",
        "        value2 = float(range_match.group(3))\n",
        "        unit2 = range_match.group(4)\n",
        "\n",
        "        # Ensure both units are the same (to be consistent)\n",
        "        if unit1 == unit2:\n",
        "            avg_value = (value1 + value2) / 2\n",
        "            return avg_value, unit1\n",
        "        else:\n",
        "            return None, None  # Flag this for further investigation\n",
        "\n",
        "    # Check for lists (e.g., '[9, 11] kilogram')\n",
        "    list_match = re.match(list_pattern, value)\n",
        "    if list_match:\n",
        "        numbers = [float(n) for n in list_match.group(1).split(',')]\n",
        "        unit = list_match.group(2)\n",
        "        avg_value = sum(numbers) / len(numbers)  # Use the average for simplicity\n",
        "        return avg_value, unit\n",
        "\n",
        "    # Check for single values (e.g., '500.0 gram')\n",
        "    single_match = re.match(single_value_pattern, value)\n",
        "    if single_match:\n",
        "        value = float(single_match.group(1))\n",
        "        unit = single_match.group(2)\n",
        "        return value, unit\n",
        "\n",
        "    # If nothing matches, return None (invalid or missing data)\n",
        "    return None, None\n",
        "\n",
        "# Apply the function to the entity_value column\n",
        "train_df['numeric_value'], train_df['unit'] = zip(*train_df['entity_value'].apply(extract_numeric_value_and_unit))\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(train_df[['entity_value', 'numeric_value', 'unit']])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao3FHaWAFSrr",
        "outputId": "e9544958-5899-4cff-aba9-954ecd7ce79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train datafframe columns :  Index(['image_link', 'group_id', 'entity_name', 'entity_value'], dtype='object')\n",
            "unique entity name:  ['item_weight' 'item_volume' 'voltage' 'wattage'\n",
            " 'maximum_weight_recommendation' 'height' 'depth' 'width']\n",
            "unique entity value:  ['500.0 gram' '1.0 cup' '0.709 gram' ... '21.38 inch' '63.3 inch'\n",
            " '4.1 metre']\n",
            "           entity_value  numeric_value        unit\n",
            "0            500.0 gram        500.000        gram\n",
            "1               1.0 cup          1.000         cup\n",
            "2            0.709 gram          0.709        gram\n",
            "3            0.709 gram          0.709        gram\n",
            "4        1400 milligram       1400.000   milligram\n",
            "...                 ...            ...         ...\n",
            "263854   5.0 centimetre          5.000  centimetre\n",
            "263855         8.5 inch          8.500        inch\n",
            "263856  43.2 centimetre         43.200  centimetre\n",
            "263857   9.1 centimetre          9.100  centimetre\n",
            "263858  27.5 centimetre         27.500  centimetre\n",
            "\n",
            "[263859 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for rows where extraction failed\n",
        "invalid_rows = train_df[train_df['numeric_value'].isna()]\n",
        "print(\"Invalid rows (failed extraction):\", invalid_rows.shape[0])\n",
        "\n",
        "# Check if there are any rows where the units didn't match in ranges\n",
        "unit_mismatch_rows = train_df[train_df['unit'].isna()]\n",
        "print(\"Rows with unit mismatch or missing data:\", unit_mismatch_rows.shape[0])\n",
        "\n",
        "# Inspect a few problematic rows (if any)\n",
        "print(invalid_rows.head())\n",
        "print(unit_mismatch_rows.head())\n",
        "\n",
        "\n",
        "# Check the shape of the cleaned dataframe\n",
        "print(f\"Original DataFrame size: {train_df.shape[0]}\")\n",
        "\n",
        "train_df = train_df.dropna(subset=['numeric_value', 'unit'])\n",
        "\n",
        "print(f\"Cleaned DataFrame size: {train_df.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igJedi1IG-1P",
        "outputId": "ca7368ae-0fe7-4245-973e-5fc61275f8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid rows (failed extraction): 3276\n",
            "Rows with unit mismatch or missing data: 3276\n",
            "                                            image_link  group_id  entity_name  \\\n",
            "139  https://m.media-amazon.com/images/I/71Oo4M3Apx...    752266      voltage   \n",
            "152  https://m.media-amazon.com/images/I/71P0BToikA...    459516  item_volume   \n",
            "169  https://m.media-amazon.com/images/I/81Qf73SxLa...    752266      voltage   \n",
            "215  https://m.media-amazon.com/images/I/71L-+M3VVP...    507619  item_weight   \n",
            "228  https://m.media-amazon.com/images/I/71iSbwHDcd...    648011      voltage   \n",
            "\n",
            "                entity_value  numeric_value  unit  \n",
            "139      [100.0, 240.0] volt            NaN  None  \n",
            "152  [8.0, 12.0] fluid ounce            NaN  None  \n",
            "169       [85.0, 265.0] volt            NaN  None  \n",
            "215       [25.0, 30.0] pound            NaN  None  \n",
            "228      [175.0, 265.0] volt            NaN  None  \n",
            "                                            image_link  group_id  entity_name  \\\n",
            "139  https://m.media-amazon.com/images/I/71Oo4M3Apx...    752266      voltage   \n",
            "152  https://m.media-amazon.com/images/I/71P0BToikA...    459516  item_volume   \n",
            "169  https://m.media-amazon.com/images/I/81Qf73SxLa...    752266      voltage   \n",
            "215  https://m.media-amazon.com/images/I/71L-+M3VVP...    507619  item_weight   \n",
            "228  https://m.media-amazon.com/images/I/71iSbwHDcd...    648011      voltage   \n",
            "\n",
            "                entity_value  numeric_value  unit  \n",
            "139      [100.0, 240.0] volt            NaN  None  \n",
            "152  [8.0, 12.0] fluid ounce            NaN  None  \n",
            "169       [85.0, 265.0] volt            NaN  None  \n",
            "215       [25.0, 30.0] pound            NaN  None  \n",
            "228      [175.0, 265.0] volt            NaN  None  \n",
            "Original DataFrame size: 263859\n",
            "Cleaned DataFrame size: 260583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify no invalid rows remain\n",
        "invalid_rows_after_cleaning = train_df[train_df['numeric_value'].isna() | train_df['unit'].isna()]\n",
        "print(f\"Invalid rows after cleaning: {invalid_rows_after_cleaning.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_SBsPXH9JU",
        "outputId": "da5df3db-7ef6-42d8-fb05-ea884c0bb4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid rows after cleaning: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_units(value, unit):\n",
        "    conversion_factors = {\n",
        "        'kilogram': 1000,  # to grams\n",
        "        'gram': 1,\n",
        "        'milligram': 1e-3,\n",
        "        'pound': 453.592,\n",
        "        'ounce': 28.3495,\n",
        "        'centimetre': 1,\n",
        "        'metre': 100,  # to centimetres\n",
        "        'millimetre': 0.1,\n",
        "        'inch': 2.54,  # to centimetres\n",
        "        'foot': 30.48,\n",
        "        'yard': 91.44,\n",
        "        'litre': 1000,  # to millilitres\n",
        "        'millilitre': 1,\n",
        "        'cup': 236.588,  # to millilitres\n",
        "        'pint': 473.176,  # to millilitres\n",
        "        # Add other conversions as necessary\n",
        "    }\n",
        "\n",
        "    if unit in conversion_factors:\n",
        "        return value * conversion_factors[unit]\n",
        "    return value\n",
        "\n",
        "# Apply the conversion to the numeric_value and unit columns\n",
        "train_df['standardized_value'] = train_df.apply(\n",
        "    lambda row: standardize_units(row['numeric_value'], row['unit']), axis=1)\n",
        "\n",
        "# Check the standardized values\n",
        "print(train_df[['entity_value', 'numeric_value', 'unit', 'standardized_value']].head(10))\n",
        "\n",
        "print(train_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oe83qgbIdio",
        "outputId": "7744a212-5dd8-414c-ada8-29022394bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     entity_value  numeric_value       unit  standardized_value\n",
            "0      500.0 gram        500.000       gram             500.000\n",
            "1         1.0 cup          1.000        cup             236.588\n",
            "2      0.709 gram          0.709       gram               0.709\n",
            "3      0.709 gram          0.709       gram               0.709\n",
            "4  1400 milligram       1400.000  milligram               1.400\n",
            "5  1400 milligram       1400.000  milligram               1.400\n",
            "6  1400 milligram       1400.000  milligram               1.400\n",
            "7  1400 milligram       1400.000  milligram               1.400\n",
            "8  1400 milligram       1400.000  milligram               1.400\n",
            "9  1400 milligram       1400.000  milligram               1.400\n",
            "Index(['image_link', 'group_id', 'entity_name', 'entity_value',\n",
            "       'numeric_value', 'unit', 'standardized_value'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_folder, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.dataframe.iloc[idx, 0].split(\"/\")[-1])\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "        except FileNotFoundError:\n",
        "            image = Image.new('RGB', (256, 256), color='gray')\n",
        "            numeric_value = 0.0\n",
        "        else:\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            numeric_value = self.dataframe.iloc[idx, 4]\n",
        "\n",
        "        # Convert numeric_value to float32\n",
        "        numeric_value = torch.tensor(numeric_value, dtype=torch.float32)\n",
        "\n",
        "        return image, numeric_value\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y8WTRlqwSlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize image\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "])\n"
      ],
      "metadata": {
        "id": "tWnrpOpULEhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_exists(image_path):\n",
        "    return os.path.exists(image_path)\n",
        "\n",
        "# Apply the filter\n",
        "train_df = train_df[train_df['image_link'].apply(lambda x: image_exists(os.path.join('train_images', x.split('/')[-1])))]\n",
        "\n",
        "\n",
        "train_dataset = ProductDataset(train_df, 'train_images', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "nIJkAZbqUX6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ProductModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ProductModel, self).__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 100)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "W_ht0sosUeWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_f1_score(true_labels, predictions):\n",
        "    y_true = np.array(true_labels)\n",
        "    y_pred = np.array(predictions)\n",
        "\n",
        "    # Compute F1 Score\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return f1\n"
      ],
      "metadata": {
        "id": "yDWACQI3Zc_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qI5IcqbEvwkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# Define the model, criterion, and optimizer\n",
        "model = ProductModel()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "num_epochs = 10\n",
        "accuracy_threshold = 0.1  # Define a threshold (e.g., 10%)\n",
        "\n",
        "# Lists to store predictions and ground truth for F1 score calculation\n",
        "all_predictions = []\n",
        "all_ground_truth = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_absolute_error = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Ensure images and labels are of float32\n",
        "            images = images.to(torch.float32)\n",
        "            labels = labels.to(torch.float32)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Ensure outputs are of float32\n",
        "            outputs = outputs.to(torch.float32)\n",
        "\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Collect predictions and ground truth\n",
        "            predictions = outputs.squeeze().detach().cpu().numpy()\n",
        "            ground_truth = labels.detach().cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_ground_truth.extend(ground_truth)\n",
        "\n",
        "            # Calculate Mean Absolute Error (MAE) for this batch\n",
        "            batch_absolute_error = torch.mean(torch.abs(outputs.squeeze() - labels)).item()\n",
        "            total_absolute_error += batch_absolute_error\n",
        "\n",
        "            # Calculate accuracy based on custom threshold\n",
        "            batch_accuracy = torch.mean(((torch.abs(outputs.squeeze() - labels) / labels) < accuracy_threshold).float()).item()\n",
        "            correct_predictions += batch_accuracy * len(labels)\n",
        "            total_predictions += len(labels)\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({'Loss': running_loss / (pbar.n + 1), 'MAE': total_absolute_error / (pbar.n + 1), 'Accuracy': correct_predictions / total_predictions})\n",
        "            pbar.update(1)\n",
        "\n",
        "    # Print epoch summary\n",
        "    avg_loss = running_loss / num_batches\n",
        "    avg_mae = total_absolute_error / num_batches\n",
        "    avg_accuracy = correct_predictions / total_predictions\n",
        "    avg_f1_score = compute_f1_score(all_ground_truth, all_predictions)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}, Accuracy: {avg_accuracy:.4f}, F1 Score: {avg_f1_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MqvOTHCIUg5D",
        "outputId": "4091b06c-674d-4826-a587-20443fcb8c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  19%|█▊        | 58/310 [14:17<1:02:07, 14.79s/batch, Loss=7.99e+22, MAE=9.14e+9, Accuracy=0.0269]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file 'train_images/716B6PlYipL.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-fe185b97d648>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-8f6341385ae5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'train_images/716B6PlYipL.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data_frame.iloc[idx, 1]  # image_link column\n",
        "        img_path = f\"{self.img_dir}/{img_name.split('/')[-1]}\"\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.data_frame.iloc[idx, 3]  # entity_name column\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = TestDataset(csv_file='test.csv', img_dir='test_images', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "JS06iahqZk9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (images, entity_names) in enumerate(test_loader):\n",
        "        images = images.to(torch.float32)\n",
        "        outputs = model(images)\n",
        "        predicted_value = outputs.item()\n",
        "\n",
        "        # Append results to predictions list\n",
        "        predictions.append({\n",
        "            'index': idx,\n",
        "            'prediction': f'{predicted_value} {entity_names[0]}'\n",
        "        })\n",
        "\n",
        "# Save predictions to CSV\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "predictions_df.to_csv('test_out.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Hf0lLi7rdL-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# # Source path (the folder you want to copy)\n",
        "# source_folder = 'drive/MyDrive/train_images'\n",
        "\n",
        "# # Destination path (where you want to copy the folder)\n",
        "# destination_folder = 'train_images'\n",
        "\n",
        "# # Copy the folder\n",
        "# shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "# print(f\"Folder copied to {destination_folder}\")\n",
        "\n",
        "# import shutil\n",
        "\n",
        "# # Source path (the folder you want to move)\n",
        "# source_folder = 'train_images'\n",
        "\n",
        "# # Destination path (where you want to move the folder)\n",
        "# destination_folder = 'drive/MyDrive/train_images'\n",
        "\n",
        "# # Move the folder\n",
        "# shutil.move(source_folder, destination_folder)\n",
        "\n",
        "# print(f\"Folder moved to {destination_folder}\")\n",
        "# import os\n",
        "\n",
        "# # Get the current directory\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# # List directories in the current directory\n",
        "# directories = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]\n",
        "\n",
        "# print(directories)\n",
        "\n",
        "\n",
        "\n",
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# folder_path = \"train_images\"\n",
        "\n",
        "# # Function to delete a folder\n",
        "# def delete_folder(folder_path):\n",
        "#     if os.path.exists(folder_path):\n",
        "#         try:\n",
        "#             shutil.rmtree(folder_path)\n",
        "#             print(f\"Folder '{folder_path}' and its contents deleted successfully.\")\n",
        "#         except OSError as e:\n",
        "#             print(f\"Error: {e.strerror}\")\n",
        "#     else:\n",
        "#         print(f\"Folder '{folder_path}' does not exist.\")\n",
        "\n",
        "# # Call the function\n",
        "# delete_folder(folder_path)"
      ],
      "metadata": {
        "id": "Lhp8yhoTuWsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, save_path='trained_model.pth'):\n",
        "    \"\"\"\n",
        "    Save the model parameters to a file.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model.\n",
        "        save_path (str): The file path to save the model parameters.\n",
        "    \"\"\"\n",
        "    # Save the model's state_dict (parameters)\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model parameters saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "FJz9ec2ty4hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, load_path='trained_model.pth'):\n",
        "    \"\"\"\n",
        "    Load the model parameters from a file.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model architecture.\n",
        "        load_path (str): The file path from which to load the model parameters.\n",
        "    \"\"\"\n",
        "    # Load the saved model state_dict into the model\n",
        "    model.load_state_dict(torch.load(load_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    print(f\"Model parameters loaded from {load_path}\")\n"
      ],
      "metadata": {
        "id": "UFghRlvEy8nI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}